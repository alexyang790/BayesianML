> priors and posteriors! 

# Bayes' Theorm 
![[Screenshot 2024-09-10 at 11.05.44.png]]
- $P(\theta|X)$ is how good our model is given data; $\theta$ could be the parameters 
- $P(\theta)$ probability of model 
- $P(X)$ probability of data; the normalizing concept
# The likelihood $P(\theta|X)$ 
- the probability of your data given a specific values of parameters $\theta$
Typically you don't need to provide the model in likelihood form 
- e.g. $y = \beta x + \epsilon$ has a likelihood of ((((fix later))))

